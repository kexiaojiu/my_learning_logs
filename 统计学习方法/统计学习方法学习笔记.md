[toc]
# 1 统计学习方法概论
## 1.1 统计学习
* 统计学习（statistical learning）是关于计算机基于数据构建概率统计模型并运用模型对数据进行预测和分析的一门学科。统计学习也称为统计机器学习（statistical machine learning）。
* 统计学习由**监督学习(supervised learning)**、非监督学习(unsupervised learning)、半监督学习(semi-supervised learning)和强化学习(reinforcement learning)等组成。
* 实现统计学习方法的步骤：
>1 得到一个有限的训练数据集合；   
>2 确定包含所有可能的模型的假设空间，即学习模型的集合；   
>3 确定模型选择的准则，即学习的策略；   
>4 实现求解最优化模型的算法，即学习的算法；   
>5 通过学习方法选择最优模型；   
>6 利用学习的最优模型对新数据进行预测或分析   

## 1.2 监督学习
* 统计学习假设数据存在一定的统计规律，X和Y具有联合概率分布*P*(*X*,*Y*);
* 监督学习的模型可以是概论模型或者非概率模型，由条件概论分布*P*(*X*|*Y*)或决策函数（decision function）*Y*=*f*(*X*)表示;
* 监督学习分为学习和预测两个过程，由学习系统与预测系统完成，如图1.1 所示
<center>![](http://i.imgur.com/JFGL2Wg.png)</center>     

<center>图1.1 监督学习问题</center>  

## 1.3 统计学习的三要素
### 1.3.1 模型(model)
在监督学习过程中，模型就是所要学习的条件概率分布或决策函数。模型的假设空间（hypothesis space）包含所有可能的条件概论分布或决策函数。   
### 1.3.2 策略(strategy)
统计学习的目标是从假设空间中选取最优模型。
(1) 损失函数和风险函数
用一个损失函数（loss function）或代价函数（cost function）来度量预测错误的程度。损失函数是*f(X)*和*Y*的非负实值函数，记作 *L(Y,f(X))*。
常用的损失函数有
* 0-1损失函数（0-1 loss function）   
<center>![1.1](http://i.imgur.com/BmmqEfs.gif)</center>

* 平方损失函数（quadratic loss function）
<center>![1.2](http://i.imgur.com/MaeVGPg.gif)</center>

* 绝对损失函数（absolute loss function）
<center>![1.3](http://i.imgur.com/ZZuVzsV.gif)</center>

* 对数损失函数（logarithmic loss function）或对数似然损失函数（loslikelihood loss function）
<center>![1.4](http://i.imgur.com/nENWaTf.gif)</center>

给定一个训练集   
<center>![1.5](http://i.imgur.com/RdjOBPm.gif)</center>   

模型*f(x)*关于训练数据集的平均损失称为经验风险（empirical risk）或经验损失（empirical loss）,记作*R<sub>emp</sub>*:   
<center>![1.6](http://i.imgur.com/Aag8wkt.gif)</center>

期望风险*R<sub>exp</sub>*是模型关于联合分布的期望损失， 经验风险*R<sub>emp</sub>* 是模型关于训练样本集的平均损失。根据大数定律，当样本容量*N*趋于无穷时，经验风险*R<sub>emp</sub>* 趋于期望风险*R<sub>exp</sub>*。
  
(2) 经验风险最小化（empirical risk minimization,ERM）与结构风险最小化（structural risk minimization, SRM）   
ERM认为，经验最小的模型就是最优的模型。 按照经验风险最小化求最优模型就是求解最优化问题：     
<center>![1.7](http://i.imgur.com/kB2odVj.gif)</center>   
其中$F$是假设空间。   
  
当模型是条件概论分布，损失函数是对数损失函数时，经验风险最小化就等价于极大似然估计。但是样本容量较小的时候，就会产生过拟合（over-fitting）现象。    

结构风险的定义是   
<center>![1.8](http://i.imgur.com/R6DIn9i.gif)</center>   
其中*J(f)* 为模型的复杂度，定义在假设空间的泛函。模型*f* 越复杂，复杂度*J(f)* 就越大。$\lambda$ 是非负系数，用以权衡经验风险和模型复杂度。

SRM认为，结构风险最小的模型就是最优的模型。所以求最优模型，就是求解最优化问题：   
<center>![1.9](http://i.imgur.com/HiXAWb0.gif)</center>   

这样，监督学习就变成了经验风险或结构化风险函数的最优化问题(1.7)和(1.9)。这时，经验或者结果风险函数就是最优化的目标函数。   

### 1.3.3 算法(algorihm)    
统计学习问题归结为最优化问题。   

## 1.4 模型评估与模型选择
### 1.4.1 训练误差与测试误差
给定两种学习方法，测试误差小的方法具有更好的预测能力，是更有效的方法。通常将学习方法对未知数据的预测能力称为泛化能力（generalization ability）。   
### 1.4.2 过拟合与模型选择
过拟合是指学习时选择的模型所含参数过多，以至于出现这一模型对已知数据预测得很好，但对未知数据预测得很差的现象。模型选择旨在避免过拟合并提高模型的预测能力。
拟合的最终目的是，测试无耻达到最小。下图描述了训练误差和测试误差与模型复杂度直接的关系。
<center>![1.2](http://i.imgur.com/zv6F9JF.png)</center>   

<center>图1.2 训练误差和测试误差与模型复杂度的关系</center>   

## 1.5 正则化与交叉验证
### 1.5.1 正则化
正则化（regularization）是结构风险最小化策略的实现，是在经验风险上加上一个正则项（regularizer）或罚项(penalty term)。   
正则化符合奥卡姆剃刀（Occam's razor）原理，即在所有可能选择的模型中，能够很好解释已知数据并且十分简单才是最好的模型。
### 1.5.2 交叉验证
如果样本数据充足，进行模型选择方法是随机将数据分为三个部分：训练集（traning set）、验证集（validation set）和测试集（test set）。但是往往，数据量不够。交叉验证（cross validation）的思想是重复使用数据，把给定的数据进行切分，将切分的数据集组合为训练集与测试集，在此基础上反复进行训练、测试已经模型选择。有三种交叉验证方法：   

* 简单交叉验证
* *S*折交叉验证（S-fold cross validation）
* 留一交叉验证（*S*=*N*的 *S*折交叉验证）

## 1.6 泛化能力
### 1.6.1 泛化误差
学习方法的泛化能力（generalization ability）是指由该方法学习到的模型对未知数据的预测能力，是学习方法本质上的重要性质。   
泛化误差（generalization error）反应了学习方法的泛化能力，通过测试误差评价学习方法的泛化能力依赖于测试数据集，不太可靠。事实上，泛化误差就是所学习到的模型的期望风险，定义为：
<center>![1.10](http://i.imgur.com/8osf0V5.gif)</center>

### 1.6.2 泛化误差上界
泛化误差上界（generalization error bound）

## 1.7 生成模型与判别模型
监督学习方法可以分为生成方法（generative approach）和判别方法（discriminative approach）。所学到的模型又成为生成模型（generative model）和判别模型（discriminative model）。   
生成方法由数据学习联合概率分布*P(X,Y)*，然后求出调节概率分布*P(Y|X)* 作为预测的模型。如朴素贝叶斯法和隐马尔可夫模型。   
判别方法由数据直接学习决策函数*f(X)*或者条件概率分布*P(Y|X)* 作为预测模型。如*k*近邻法、感知机、决策树、逻辑斯谛回归模型、最大熵模型、支持向量机、提升方法和条件随机场等。   

## 1.8 分类问题
监督学习从数据中学习一个分类模型或分类决策函数，称为分类器（classifier）。分类器对新的输入进行输出的预测（prediction），称为分类（classification）。下图是分类问题模型。
<center>![1.3](http://i.imgur.com/hWpgGwP.png)</center>   
<center>图1.3 分类问题</center>

对于二类分类问题常用的标准是精确率（precision）和召回率（recall）。通常以关注的类分为正类，其他类分为负类，分类器在测试数据集上的预测结果分为四种情况：   

* TP-将正类预测为正类数；
* FN-将正类预测为负类数；
* FP-将负类预测为正类数；
* TN-将负类预测为负类数。   

精确率定义为：
<center>![1.11](http://i.imgur.com/jhjnnk6.gif)</center>

召回率定义为：
<center>![1.12](http://i.imgur.com/Dl13LDW.gif)</center>

此外还有*F*<sub>1</sub> 是，精确率和召回率调和均值：
<center>![1.13](http://i.imgur.com/FsCEKUJ.gif)</center>
   
## 1.9 标注问题
下图是标注问题模型
<center>![1.4](http://i.imgur.com/KuNNQiS.png)</center>   
<center>图1.4 标注问题</center>   

标注常用的统计学习方法：隐马尔科夫模型、条件随机场。   

## 1.10 回归问题
回归(regression)用于预测输入变量和输出变量之间的关系，特别是当输入变量的值发生变化时，输出变量的值随之发生的变化。   
<center>![1.5](http://i.imgur.com/z77rIc3.png)</center>
<center>图1.5 回归问题</center>  

回归学习常用的是损失函数是平方损失函数，此时，回归问题可以用最小二乘法（least squares）求解。

----  
# 2 感知机